{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn-v0_8') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПОСТРОЕНИЕ КРИВОЙ ОБУЧЕНИЯ\n",
    "\n",
    "Давайте научимся строить кривые обучения с помощью Python. \n",
    "\n",
    "Для вычисления точек для построения кривых обучения в модуле model_selection библиотеки sklearn есть функция learning_curve().\n",
    "\n",
    "Основные параметры функции learning_curve():\n",
    "\n",
    "- estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "- X — матрица наблюдений.\n",
    "- y — вектор-столбец правильных ответов.\n",
    "- train_sizes — относительное (долевое) или абсолютное количество обучающих примеров, которые будут использоваться для создания кривой обучения. Если dtype имеет значение float, он рассматривается как часть максимального размера обучающего набора (который определяется выбранным методом проверки), т. е. он должен быть в пределах (0, 1].\n",
    "\n",
    "По умолчанию используется список [0.1, 0.325, 0.55, 0.775, 1.0], то есть для построения кривой обучения используется пять точек. Первая точка кривой обучения строится по 10 % наблюдений из обучающего набора, вторая точка — по 32.5 % и так далее до тех пор, пока в построении модели не будет участвовать весь обучающий набор данных.\n",
    "- cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация k-fold на пяти фолдах.\n",
    "- scoring — название метрики в виде строки либо функция для её вычисления.\n",
    "Если передать функции все необходимые параметры, она вернёт три массива:\n",
    "\n",
    "Список из размеров тренировочного набора (ось абсцисс кривой обучения).\n",
    "Матрица из метрик, полученных при разных размерах тренировочного набора во время кросс-валидации на тренировочных фолдах. В строках этой таблицы указаны списки метрик, соответствующие каждому размеру тренировочного набора данных, а внутри списков находятся сами метрики на кросс-валидации.\n",
    "Матрица из метрик, полученных при разных размерах тренировочного набора во время кросс-валидации на валидационных фолдах.\n",
    "Код для вычисления координат будет иметь следующий вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    class_weight='balanced', \n",
    "    random_state=42, #генератор случайных чисел \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Вычисляем координаты для построения кривой обучения\n",
    "train_sizes, train_scores, valid_scores = model_selection.learning_curve(\n",
    "    estimator = model, #модель\n",
    "    X = X, #матрица наблюдений X\n",
    "    y = y, #вектор ответов y\n",
    "    cv = skf, #кросс-валидатор\n",
    "    scoring = 'f1' #метрика\n",
    ")\n",
    "print('Train sizes: \\n', train_sizes)\n",
    "print('Train scores: \\n', train_scores)\n",
    "print('Valid scores: \\n', valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы вычислить среднюю кросс-валидационную метрику на каждом из наборов данных, необходимо рассчитать среднее по столбцам матриц train_scores и valid_scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    " \n",
    "print('Train k-fold f1 scores',  train_scores_mean)\n",
    "print('Valid k-fold f1 scores',  valid_scores_mean)\n",
    " \n",
    "## Train k-fold f1 scores [0.74181818 0.84282405 0.78703798 0.75046111 0.74357833]\n",
    "## Valid k-fold f1 scores [0.31290946 0.54221938 0.59712148 0.6403136  0.65931273]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно построить графики кривых обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Визуализируем кривую обучения\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура + координатная плоскость\n",
    "#Строим кривую обучения по метрикам на тренировочных фолдах\n",
    "ax.plot(train_sizes, train_scores_mean, label='Train')\n",
    "#Строим кривую обучения по метрикам на валидационных фолдах\n",
    "ax.plot(train_sizes, valid_scores_mean, label='Valid')\n",
    "#Даём название графику и подписи осям\n",
    "ax.set_title('Learning curve')\n",
    "ax.set_xlabel('Train data size')\n",
    "ax.set_ylabel('Score')\n",
    "#Устанавливаем отметки по оси абсцисс\n",
    "ax.xaxis.set_ticks(train_sizes)\n",
    "#Устаналиваем диапазон оси ординат\n",
    "ax.set_ylim(0, 1)\n",
    "#Отображаем легенду\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в процессе увеличения количества наблюдений в обучающем наборе данных, метрики на тренировочной и валидационной выборках постепенно приближаются друг к другу, то есть уменьшается разброс (variance).\n",
    "\n",
    "На финальном этапе, при использовании всех 2 620 наблюдений из обучающей выборки, разница в показателях между тренировочной и валидационной выборками всё ещё присутствует, однако эту разницу можно принять как случайную.\n",
    "\n",
    "Для удобства дальнейшего использования описанных выше действий для построения кривой обучения давайте обернём их в функцию plot_learning_curve(). У функции будет несколько аргументов: модель, набор данных (X, y), кросс-валидатор, метрика, координатная плоскость matplotlib, на которой будет строиться график, и подпись графика:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, X, y, cv, scoring=\"f1\", ax=None, title=\"\"):\n",
    "    # Вычисляем координаты для построения кривой обучения\n",
    "    train_sizes, train_scores, valid_scores = model_selection.learning_curve(\n",
    "        estimator=model,  # модель\n",
    "        X=X,  # матрица наблюдений X\n",
    "        y=y,  # вектор ответов y\n",
    "        cv=cv,  # кросс-валидатор\n",
    "        scoring=scoring,  # метрика\n",
    "    )\n",
    "    # Вычисляем среднее значение по фолдам для каждого набора данных\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    # Если координатной плоскости не было передано, создаём новую\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))  # фигура + координатная плоскость\n",
    "    # Строим кривую обучения по метрикам на тренировочных фолдах\n",
    "    ax.plot(train_sizes, train_scores_mean, label=\"Train\")\n",
    "    # Строим кривую обучения по метрикам на валидационных фолдах\n",
    "    ax.plot(train_sizes, valid_scores_mean, label=\"Valid\")\n",
    "    # Даём название графику и подписи осям\n",
    "    ax.set_title(\"Learning curve: {}\".format(title))\n",
    "    ax.set_xlabel(\"Train data size\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    # Устанавливаем отметки по оси абсцисс\n",
    "    ax.xaxis.set_ticks(train_sizes)\n",
    "    # Устанавливаем диапазон оси ординат\n",
    "    ax.set_ylim(0, 1)\n",
    "    # Отображаем легенду\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Вы можете сохранить написанную нами функцию и обращаться к ней в своих задачах. Она не раз вам пригодится в исследованиях.\n",
    "\n",
    "Теперь, когда у нас есть наша функция, давайте построим кривые обучения для нескольких моделей. Будем использовать следующие модели:\n",
    "\n",
    "логистическую регрессию,\n",
    "дерево решений с ограниченной максимальной глубиной и количеством объектов в листе,\n",
    "дерево решений без ограничений.\n",
    "Создадим список, в котором будем хранить эти модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём список из моделей\n",
    "models = [\n",
    "    linear_model.LogisticRegression(\n",
    "        max_iter=1000, #количество итераций на сходимость\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "    tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', #критерий информативности\n",
    "        max_depth=7, #максимальная глубина\n",
    "        min_samples_leaf=5, #минимальное число объектов в листе\n",
    "        random_state=42, #генератор случайных чисел \n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "    tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', #критерий информативности\n",
    "        random_state=42, #генератор случайных чисел \n",
    "        class_weight='balanced' #веса классов\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, построим кривые обучения для каждой из моделей. Для этого заранее создадим k-fold-кросс-валидатор со стратификацией на пять фолдов. Создадим фигуру с тремя координатными плоскостями. Реализуем цикл по составленному списку из моделей и их индексам (они нам понадобятся для отображения на соответствующих координатных плоскостях). Внутри цикла будем вызывать нашу функцию plot_learning_curve():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "#Визуализируем кривые обучения\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4)) #фигура + 3 координатных плоскости\n",
    "#Создаем цикл по списку моделей и индексам этого списка\n",
    "for i, model in enumerate(models): #i-текущий индекс, model - текущая модель\n",
    "    plot_learning_curve(\n",
    "        model, X, y, \n",
    "        skf, \n",
    "        ax=axes[i], \n",
    "        title=model.__class__.__name__ + '()'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
