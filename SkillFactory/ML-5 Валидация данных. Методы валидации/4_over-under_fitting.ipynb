{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn-v0_8') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload datas\n",
    "water_data = pd.read_csv('data/water_potability.csv')\n",
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))\n",
    "#Let's show datas\n",
    "water_data.head()\n",
    "#Devide the table\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Недообучение и переобучение. Утечка данных\n",
    "\n",
    "Обобщающая способность часто страдает из-за двух основных проблем машинного обучения: overfitting (переобучение) и underfitting (недообучение).\n",
    "\n",
    "Рассмотрим пример. Будем использовать тот же набор данных об образцах воды.\n",
    "\n",
    "Сначала проверим модель на переобучение с помощью отложенной (hold-out) выборки.\n",
    "\n",
    "Для этого стратифицированно разобьём набор данных на тренировочную и валидационную выборки в соотношении 80/20 и обучим дерево решений с энтропией  в качестве критерия информативности и сбалансированными весами классов без ограничения его глубины и количества объектов в листе. Сделаем предсказание для каждой из выборок и рассчитаем метрику F1-score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 score: 1.00\n",
      "Valid F1 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "#Создаём модель\n",
    "model_bad = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    class_weight='balanced', #веса классов\n",
    "    random_state=42 #генератор случайных чисел\n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model_bad.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model_bad.predict(X_train)\n",
    "y_valid_pred = model_bad.predict(X_valid)\n",
    "#Выводим значения метрик для тренировочной выборки\n",
    "print('Train F1 score: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "#Выводим значения метрик для валидационной выборки\n",
    "print('Valid F1 score: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    " \n",
    "# Train F1 score: 1.00\n",
    "# Valid F1 score: 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это типичная картина переобучения: модель дерева решений полностью адаптировалась под обучающий набор данных, но не нашла общих закономерностей, поэтому результаты на контроле оставляют желать лучшего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0309968 , 0.02800488, 0.0285089 , 0.02899456, 0.02802825]),\n",
       " 'score_time': array([0.00300765, 0.00300312, 0.00200391, 0.002002  , 0.00205612]),\n",
       " 'test_score': array([0.61445783, 0.68421053, 0.62332696, 0.63276836, 0.70119522]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model_bad, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В полученном словаре невооруженным глазом видно, что на тренировочных фолдах значения метрик равны 1, а вот на валидационных метрика ни разу не превысила значения 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 1.00\n",
      "Valid k-fold mean f1: 0.65\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 1.00\n",
    "## Valid k-fold mean f1: 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МЕТОДЫ БОРЬБЫ С ПЕРЕОБУЧЕНИЕМ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На реальных данных, подверженных зашумлённости, такой подход в большинстве случаев приводит к переобучению дерева: глубина становится очень большой, и дерево не отражает общих зависимостей в данных.\n",
    "\n",
    "В таком случае в первую очередь прибегают к «обрезке» деревьев путём ограничения максимальной глубины и/или увеличения количества объектов, при которых вершина дерева превращается в лист и деление прекращается.\n",
    "\n",
    "Для начала посмотрим на текущую глубину дерева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current depth: 27\n"
     ]
    }
   ],
   "source": [
    "print('Current depth:', model_bad.get_depth())\n",
    "## Current depth: 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.75\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "\n",
    "\n",
    "## Train k-fold mean f1: 0.75\n",
    "## Valid k-fold mean f1: 0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После ограничения максимальной глубины удалось уменьшить разницу между метриками на тренировочных и валидационных фолдах кросс-валидации.\n",
    "\n",
    "Попробуем добавить ещё одно ограничение к нашему дереву: увеличим количество объектов, которых достаточно для образования листа дерева (min_samples_leaf). По умолчанию этот параметр равен 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean f1: 0.74\n",
      "Valid k-fold mean f1: 0.66\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #ограничиваем глубину дерева\n",
    "    min_samples_leaf=5, #увеличиваем количество объектов в листе\n",
    "    random_state=42, #генератор случайных чисел\n",
    "    class_weight='balanced' #веса классов\n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора k-fold со стратификацией\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold со стратификацией\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=skf, #кросс-валидатор\n",
    "    scoring='f1', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean f1: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    "## Train k-fold mean f1: 0.74\n",
    "## Valid k-fold mean f1: 0.66"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
